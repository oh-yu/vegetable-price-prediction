{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7252c6a8-070b-4816-94a1-bd88b5d94ce2",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5ec26b8-542d-4d31-b187-97665d27c890",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ray import tune\n",
    "from ray.tune.suggest.hyperopt import HyperOptSearch\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.integration.wandb import WandbLogger\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70e8bdde-23ff-41a2-826c-d86ee17c0e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f272e5-7075-4f5e-be21-681afbdce81d",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb4f2b86-3027-4342-84ef-e20ba8b69aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_rnn_raytune(config, options):    \n",
    "    # Assign Config, Options\n",
    "    training_size = options[\"training_size\"]\n",
    "    target_values = options[\"target_values\"]\n",
    "    \n",
    "    lr = config[\"lr\"]\n",
    "    weight_decay = config[\"weight_decay\"]\n",
    "    eps = config[\"eps\"]\n",
    "    num_epochs = config[\"num_epochs\"]\n",
    "    batch_size = config[\"batch_size\"]\n",
    "    \n",
    "    # Preprocess Data\n",
    "    train_loader, test_y, train, test, ss = utils.preprocess_data(target_values, train_size=training_size, batch_size=batch_size)\n",
    "\n",
    "    # Instantiate Model, Optimizer, Criterion, EarlyStopping\n",
    "    model = utils.RNN(input_size=train.shape[2]).to(DEVICE)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay, eps=eps)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Training & Test Loop\n",
    "    for _ in range(num_epochs):\n",
    "        model.train()\n",
    "\n",
    "        for _, (batch_x, batch_y) in enumerate(train_loader):\n",
    "            # Forward\n",
    "            out = model(batch_x)\n",
    "            loss = criterion(out, batch_y)\n",
    "\n",
    "            # Backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            # Update Params\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "            optimizer.step()\n",
    "\n",
    "        # Test\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            pred_y = model.predict(train, test, test.shape[0])\n",
    "            pred_y = pred_y.reshape(-1)\n",
    "            loss = criterion(pred_y, test_y)\n",
    "            tune.report(loss=loss.item())\n",
    "\n",
    "def pipeline_raytune(options, config, trainer=pipeline_rnn_raytune):\n",
    "    \n",
    "    # Instantiate HyperOptSearch, ASHAScheduler\n",
    "    hyperopt = HyperOptSearch(metric=\"loss\", mode=\"min\")\n",
    "    scheduler = ASHAScheduler(\n",
    "        metric='loss', mode='min', max_t=1000,\n",
    "        grace_period=12, reduction_factor=2\n",
    "    )\n",
    "    \n",
    "    # Optimization\n",
    "    analysis = tune.run(\n",
    "        partial(trainer, options=options),\n",
    "        config=config,\n",
    "        num_samples=100,\n",
    "        search_alg=hyperopt,\n",
    "        resources_per_trial={'cpu':4, 'gpu':1},\n",
    "        scheduler=scheduler,\n",
    "        loggers=[WandbLogger]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd24a900-9932-4c91-b771-b985abc77173",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27abf787-af8e-4aee-a1e1-5a3075b6101f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_vegetable = \"トマト\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3c21660-49fa-4b14-b86a-04458dd42e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test = pd.read_csv(\"./data/mapped_train_test.csv\")\n",
    "train_test[\"date\"] = pd.to_datetime(train_test[\"date\"], format=\"%Y-%m-%d\")\n",
    "weather = pd.read_csv(\"./data/sorted_mapped_adjusted_weather.csv\")\n",
    "train_test = pd.concat([train_test, weather], axis=1)\n",
    "\n",
    "train_test[\"year\"] = train_test.date.dt.year\n",
    "years = pd.get_dummies(train_test[\"year\"])\n",
    "train_test = train_test.drop(columns=\"year\")\n",
    "train_test = pd.concat([train_test, years], axis=1)\n",
    "\n",
    "train_test[\"month\"] = train_test.date.dt.month\n",
    "months = pd.get_dummies(train_test[\"month\"])\n",
    "train_test = train_test.drop(columns=\"month\")\n",
    "train_test = pd.concat([train_test, months], axis=1)\n",
    "\n",
    "# train_test[\"weekday\"] = train_test.date.dt.weekday\n",
    "# weekdays = pd.get_dummies(train_test[\"weekday\"])\n",
    "# train_test = train_test.drop(columns=\"weekday\")\n",
    "# train_test = pd.concat([train_test, weekdays], axis=1)\n",
    "\n",
    "areas = pd.get_dummies(train_test[\"area\"])\n",
    "train_test = train_test.drop(columns=\"area\")\n",
    "train_test = pd.concat([train_test, areas], axis=1)\n",
    "\n",
    "train = train_test[:pd.read_csv(\"./data/train.csv\").shape[0]]\n",
    "\n",
    "target_values = utils.get_target_values(train, target_vegetable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef185d00-80c6-4479-a88d-361d754702f2",
   "metadata": {},
   "source": [
    "# Set Config, Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70f154e8-0616-4c0e-a9e0-21f952c5c9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_options = {\n",
    "    \"target_values\": target_values,\n",
    "    \"training_size\": 4000,\n",
    "}\n",
    "\n",
    "rnn_config = {\n",
    "    \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "    \"weight_decay\": tune.choice([0, 1e-10, 1e-7, 1e-5, 1e-3]),\n",
    "    \"eps\": tune.choice([1e-11, 1e-8, 1e-5, 1e-3, 1e-1]),\n",
    "    \"num_epochs\": tune.choice([25, 50, 75, 100, 150]),\n",
    "    \"batch_size\": tune.choice([16, train.shape[0]]),\n",
    "    \"wandb\": {\n",
    "        \"project\": f\"{target_vegetable}\",\n",
    "        \"api_key_file\": \"./wandb_api_key.txt\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5211087c-5552-4035-95eb-48178141e90d",
   "metadata": {},
   "source": [
    "# Raytune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f694fac3-a25b-47ce-a53c-363fd1a2c77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_raytune(rnn_options, rnn_config, trainer=pipeline_rnn_raytune)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
